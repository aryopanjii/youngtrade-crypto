# -*- coding: utf-8 -*-
"""Clustering Crypto.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qVCm074mKZTRzuwhtS24-uO9SGcNFASm
"""

apikey = 'K8AF2wV5T0z1Pi6YHFFiOvLPnY5MdAKtjIN8AfRfTEFCXzsF8nxC38vwyD6yTkeV'
secret = 'Aryomadan123'

!pip install python-binance pandas mplfinance

from binance import Client, ThreadedWebsocketManager, ThreadedDepthCacheManager
import pandas as pd

client = Client(apikey, secret)
tickers = client.get_all_tickers()

ticker_df = pd.DataFrame(tickers)

ticker_df_symbol = ticker_df.drop(columns='price', axis=1)
ticker_df_symbol

"""#TEST

##Getting Data - Hanya Testing bagian kedua yang bener
"""

historical = client.get_historical_klines('LITUSDT', Client.KLINE_INTERVAL_1DAY, '1 Jan 2011')
hist_df_LIT = pd.DataFrame(historical)
hist_df_LIT.columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']

hist_df_LIT['Open Time'] = pd.to_datetime(hist_df_LIT['Open Time']/1000, unit='s')

hist_df_LIT.rename(columns = {"Open Time":"Date"}, inplace=True)
hist_df_LIT.rename(columns = {"Open Time":"Date"}, inplace=True)
hist_df_LIT = hist_df_LIT.set_index('Date')
#hist_df_LIT = hist_df_LIT[['Close']]

#hist_df_LIT.drop(columns='Unnamed: 0', inplace=True)
hist_df_LIT.drop(columns='Ignore', inplace=True)
#hist_df_LIT.rename(columns = {'Close':'Close_LIT'}, inplace=True)
hist_df_LIT = hist_df_LIT
hist_df_LIT



#RSR = RSR.set_index('Date')
#LIT = LIT[['Close']]
LIT.drop(columns='Unnamed: 0', inplace=True)
LIT.drop(columns='Ignore', inplace=True)
LIT.rename(columns = {'Close':'Close_LIT'}, inplace=True)
LIT.shape

#hist_df_SHIB_new2 = hist_df_SHIB[['Open Time','Close']]
hist_df_SHIB['Open Time'] = pd.to_datetime(hist_df_SHIB['Open Time']/1000, unit='s')
#hist_df_SHIB_new2 = hist_df_SHIB_new2.set_index('Open Time')
#hist_df_SHIB_new2.rename(columns= {"Close":"Close_shib"}, inplace=True)
hist_df_SHIB_new2

""">> test"""

f'ticker_df_symbol_{symbols}'

ticker_df_symbol_DOGERUB

""">>test

#Getting data from each crypto into list
"""

ticker_df_symbol

# mendapatkan nama symbols (currency)|
for symbols in ticker_df_symbol['symbol']:
    print(symbols)

from google.colab import drive
drive.mount('/content/gdrive')

def myfunction(data):
  print(data)
file_path = '/content/drive/My Drive/saham'

for symbols in ticker_df_symbol['symbol']:
    # nama variabel berdasarkan currency
    dataframe_identity = f'ticker_df_symbol_{symbols}' # hanya sebuah string
    
    # string / nama variable, dijadikan variable
    
    # saya gunakan string yang telah didefine sebelumnya, menjadi nama variable
    globals()[dataframe_identity] = pd.DataFrame( client.get_historical_klines(symbols, Client.KLINE_INTERVAL_1DAY, '1 Jan 2011') )
    globals()[dataframe_identity].columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']
    globals()[dataframe_identity]['Open Time'] = pd.to_datetime(globals()[dataframe_identity]['Open Time']/1000, unit='s')
    #hist_df['Close Time'] = pd.to_datetime(hist_df['Close Time']/1000, unit='s')
    #historical = client.get_historical_klines('ETHBTC', Client.KLINE_INTERVAL_1DAY, '1 Jan 2011')
                   #'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']

"""--> Test for merge all dataframe into one dataframe"""

for symbols in symbol_only_usdt['symbol']:
  dataframe_identity = f'ticker_df_symbol_{symbols}'

#Perulangan untuk menjadikan 1 dataframe result

result = pd.concat([BTC, LTC], axis=1, join="inner")
result.rename(columns = {"Open Time": "Date", "Close": "CloseBTC","Close":"CloseLTC"}, inplace=True)
result

"""only usdt pairing will to put on dataframe"""

symbol_only_usdt = ticker_df_symbol[ticker_df_symbol['symbol'].str.contains("USDT")]

for symbols in symbol_only_usdt['symbol']:
    # nama variabel berdasarkan currency
    dataframe_identity = f'symbol_only_usdt{symbols}' # hanya sebuah string
    
    # string / nama variable, dijadikan variable
    
    # saya gunakan string yang telah didefine sebelumnya, menjadi nama variable
    globals()[dataframe_identity] = pd.DataFrame( client.get_historical_klines(symbols, Client.KLINE_INTERVAL_1DAY, '1 Jan 2011') )
    globals()[dataframe_identity].columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']
    globals()[dataframe_identity]['Open Time'] = pd.to_datetime(globals()[dataframe_identity]['Open Time']/1000, unit='s')
    eval(f'ticker_df_symbol_{symbols}').to_csv('/content/gdrive/MyDrive/digitalskola/dataset/babp/lengkap/'f'ticker_df_symbol_{symbols}.csv')
    # ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
   
    #hist_df['Close Time'] = pd.to_datetime(hist_df['Close Time']/1000, unit='s')
    #historical = client.get_historical_klines('ETHBTC', Client.KLINE_INTERVAL_1DAY, '1 Jan 2011')

    # ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    #'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']

symbol_only_usdt

"""#Perulangan Dataframe USDT menjadi satu dataframe (FIX) 14 sept 2022 Rabu"""

#symbol_only_usdtBTCUSDT mau ambil data close dan date saja
KNC_1 = pd.DataFrame(hist_df_KNC[['Open Time','Close']])

symbol_only_usdt = ticker_df_symbol[ticker_df_symbol['symbol'].str.contains("USDT")] # --> for filter only USDT pair 
result =pd.DataFrame(columns = ['Open Time','close'])                                # --> New Dataframe for temporary Dataframe 
result = BTC_1                                                                       #BTC_! already having 2 column only --> Date and Close price

for symbols in symbol_only_usdt['symbol']:
    # nama variabel berdasarkan currency
    dataframe_identity = f'symbol_only_usdt{symbols}' # hanya sebuah string
    
    # string / nama variable, dijadikan variable
    
    # saya gunakan string yang telah didefine sebelumnya, menjadi nama variable
    globals()[dataframe_identity] = pd.DataFrame( client.get_historical_klines(symbols, Client.KLINE_INTERVAL_1DAY, '1 Jan 2011') )
    globals()[dataframe_identity].columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']
    globals()[dataframe_identity]['Open Time'] = pd.to_datetime(globals()[dataframe_identity]['Open Time']/1000, unit='s')
    Data_a = pd.DataFrame(globals()[dataframe_identity][['Open Time','Close']])
    Data_b = Data_a.rename(columns = {'Close':dataframe_identity}, inplace = True)
    result = pd.merge(result,Data_a, how='left', on=['Open Time'])

#menghapus crypto yang memiliki 50% data null valuye untuk mengurangi noise
#df.drop('A', axis=1, inplace=True)
result.drop('symbol_only_usdtBCCUSDT', axis=1, inplace=True)

result.to_csv('/content/gdrive/MyDrive/digitalskola/dataset/babp/hasilmerge_cryptoAPIBinance_422coin.csv')

result3 = result
result3.copy()

"""## Finding missing value"""

#result3[result3.columns[1]].count() 1000 row

for i in range(0,249):
  dataframe_identity = result3.columns[i]
  if (result3[result3.columns[i]].count() < 1000):
    print(dataframe_identity,'true')
    #result3[[dataframe_identity]]
    result3.drop(result3[[dataframe_identity]], axis=1, inplace=True)
    #result3.drop(result3[result3.columns[i]], axis=1, inplace=True)
    #print(dataframe_identity,' = ',result3[result3.columns[i]].count())
  #globals()[dataframe_identity] = pd.DataFrame(dataframe_identity)

#result3[result3.columns[1]].count() 700 row

for i in range(0,166):
  dataframe_identity = result3.columns[i]
  if (result3[result3.columns[i]].count() < 700):
    print(dataframe_identity,'true')
    #result3[[dataframe_identity]]
    result3.drop(result3[[dataframe_identity]], axis=1, inplace=True)
    #result3.drop(result3[result3.columns[i]], axis=1, inplace=True)
    #print(dataframe_identity,' = ',result3[result3.columns[i]].count())
  #globals()[dataframe_identity] = pd.DataFrame(dataframe_identity)

for i in range(0,422):
  dataframe_identity = result3.columns[i]
  if (result3[result3.columns[i]].count() < 700):
    print(dataframe_identity,' = ',result3[result3.columns[i]].count())
    result3.drop(result3[[dataframe_identity]], axis=1, inplace=True)

"""### jalanin ini berulang hingga tersisa 108 column dari 400 column dan ini harus dijalankan berulang"""

for i in range(0,422):
  dataframe_identity = result3.columns[i]
  if (result3[result3.columns[i]].count() < 700):
    print(dataframe_identity,' = ',result3[result3.columns[i]].count())
    result3.drop(result3[[dataframe_identity]], axis=1, inplace=True)

"""### Berishkan Close columns dan menjadikan open time menjadikan index dan nomer index di hapus"""

result3.drop('Close', axis=1, inplace=True)

local_df = result3.copy(deep=True) #cadangan aja

#menjadikan date time menjadi index
data1_new = result3.set_index('Open Time')

data1_new.to_csv('/content/gdrive/MyDrive/digitalskola/dataset/babp/Datacryptocluster_100crypto.csv')

data1_new

""">> data1_new.to_csv('/content/gdrive/MyDrive/digitalskola/dataset/babp/Datacryptocluster_100crypto.csv') ini bersih

lalu untuk set index nya bisa menggunakan 
data1_new = result.set_index('Open Time') 
supaya index column number di open time bisa dihapus

### Uji Statistik --> continue
"""

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
path = '/content/gdrive/MyDrive/digitalskola/dataset/babp/Datacryptocluster_100crypto.csv'
result = pd.read_csv(path)
result1 = result.set_index('Open Time')
result1.head(5)

#result1.T

"""### Null Value"""

sns.boxplot(result1.symbol_only_usdtBTCUSDT)
sns.distplot(result1.symbol_only_usdtBTCUSDT)

for i in range(result1.shape[1]):
	# count number of rows with missing values
	n_miss = result1[[i]].isna().sum()
	perc = n_miss / result1.shape[0] * 100
	print('> %d, Missing: %d (%.1f%%)' % (i, n_miss, perc))

"""### VISUALIZE (BTC - Pair)"""

import matplotlib.pyplot as plt
import seaborn as sns

#ticker_df_symbol_BTCUSDT.csv

import pandas as pd
path = '/content/gdrive/MyDrive/digitalskola/dataset/babp/Ticker500USDT/ticker_df_symbol_BTCUSDT.csv'
BTC = pd.read_csv(path)

BTC.rename(columns = {"Open Time":"Date"}, inplace=True)
BTC = BTC.set_index('Date')
BTC = BTC[['Close']]
BTC.rename(columns = {'Close':'Close_BTC'}, inplace=True)
BTC.shape

"""####Ploting RSR dengan BTC"""

#ploting RSR
import sklearn.linear_model as sk

BTC_RSR = BTC[1106:]

import pandas as pd
path = '/content/gdrive/MyDrive/digitalskola/dataset/babp/Ticker500USDT/ticker_df_symbol_RSRUSDT.csv'
RSR = pd.read_csv(path)

RSR.rename(columns = {"Open Time":"Date"}, inplace=True)
RSR = RSR.set_index('Date')
RSR = RSR[['Close']]
RSR.rename(columns = {'Close':'Close_RR'}, inplace=True)
RSR.shape

BTC_RSR.rename(columns={"Close":"Close_BTC"},inplace=True)

#RSR 760ROW DIBANDINGKAN DENGAN BTC DENGAN ROW SAMA BTC[1106:] PER TANGGAL 25
plt.scatter(BTC_RSR['Close'],RSR['Close'], color="red")
plt.xlabel("BTC")
plt.ylabel("RSR")
plt.show()

RSR_BTC = pd.merge(RSR, BTC, how='inner', on=['Date'])

reg = sk.LinearRegression()

reg.fit(RSR_BTC[['Close_RR']],RSR_BTC['Close_BTC'])

#reg.coef_
plt.scatter(RSR_BTC['Close_RR'],RSR_BTC['Close_BTC'], color="red")
plt.plot(RSR_BTC[['Close_RR']],reg.predict(RSR_BTC[['Close_BTC']], color='Blue', Linewidht=3)
#plt.xlabel("Close_RR")
#plt.ylabel("Close_BTC")
plt.show()

"""####Ploting Shiba dengan BTC"""

import sklearn.linear_model as sk

import pandas as pd
path = '/content/gdrive/MyDrive/digitalskola/dataset/babp/Ticker500USDT/ticker_df_symbol_SHIBUSDT.csv'
hist_df_SHIB_new2 = pd.read_csv(path)


hist_df_SHIB_new2.rename(columns = {"Open Time":"close_shib"}, inplace=True)
hist_df_SHIB_new2 = hist_df_SHIB_new2.set_index('close_shib')
hist_df_SHIB_new2.head(2)

reg = sk.LinearRegression()

reg.fit(hist_df_SHIB_new22[['Close_shib']],symbol_only_usdtBTCUSDT['Close_BTC'])

reg.coef_

plt.scatter(result1['symbol_only_usdtBTCUSDT'],result1['symbol_only_usdtBNBUSDT'], color="red")
plt.xlabel("symbol_only_usdtBTCUSDT")
plt.ylabel("symbol_only_usdtBNBUSDT")
plt.show()

#jangan dijalankan hanya sebagai comment
symbol_only_usdtBTCUSDT = pd.DataFrame(result1['symbol_only_usdtBTCUSDT'])
symbol_only_usdtBTCUSDT = symbol_only_usdtBTCUSDT[1424:]
symbol_only_usdtBTCUSDT.rename(columns= {"symbol_only_usdtBTCUSDT":"Close_BTC"}, inplace=True)
symbol_only_usdtBTCUSDT

#cara manual
hist_df_SHIB_new2.shape
hist_df_SHIB_new22 = hist_df_SHIB_new2[:431]
hist_df_SHIB_new22

import pandas as pd
path = '/content/gdrive/MyDrive/digitalskola/dataset/babp/Ticker500USDT/Datacryptocluster_100crypto.csv'
result = pd.read_csv(path)
result1 = result.set_index('Open Time')
result1.head(5)

correlation_matrix = result1.corr().round(2)
fig, ax = plt.subplots(figsize=(50,50)) 
sns.heatmap(data=correlation_matrix, annot=True, ax=ax)

plt.scatter(X_test, y_test, color = "black")
plt.plot(X_test, predictions, color = "blue")
plt.title("Regression Model: GRLivArea x SalePrice")
plt.xlabel("GRLivArea")
plt.ylabel('symbol_only_usdtBTCUSDT')
model.summary()

"""####Ploting KNC dengan BTC"""



"""#### visualize all"""

df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', parse_dates=['date'], index_col='date')

#ploting RSR 2
import sklearn.linear_model as sk

BTC_RSR = BTC[1106:]

import pandas as pd
path = '/content/gdrive/MyDrive/digitalskola/dataset/babp/Ticker500USDT/ticker_df_symbol_RSRUSDT.csv'
RSR = pd.read_csv(path, parse_dates=['Open Time'], index_col='Open Time')

#RSR = RSR.set_index('Open Time')
RSR.rename(columns = {"Open Time":"Date"}, inplace=True)

RSR = RSR[['Close']]
RSR.rename(columns = {'Close':'Close_RR'}, inplace=True)
#RSR.shape
RSR

# Multiplicative Decomposition 
result_mul = seasonal_decompose(RSR['Close_RR'], model='multiplicative', extrapolate_trend='freq')

# Additive Decomposition
result_add = seasonal_decompose(RSR['Close_RR'], model='additive', extrapolate_trend='freq')

# Plot
plt.rcParams.update({'figure.figsize': (10,10)})
result_mul.plot().suptitle('Multiplicative Decompose', fontsize=22)
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()

import seaborn as sns
# Draw Plot
fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)
sns.boxplot(x='year', y='value', data=df, ax=axes[0])
sns.boxplot(x='month', y='value', data=df.loc[~df.year.isin([1991, 2008]), :])

# Set Title
axes[0].set_title('Year-wise Box Plot\n(The Trend)', fontsize=18); 
axes[1].set_title('Month-wise Box Plot\n(The Seasonality)', fontsize=18)
plt.show()

"""#### LIT

https://github.com/dataquestio/project-walkthroughs/blob/master/sp_500/market_prediction.ipynb

https://www.youtube.com/watch?v=1O_BenficgE&list=PLq14-mgmFqECrz1TaB9Q2JlQB-RzxN9Vh&index=4&t=1889s
"""

#ploting RSR
import sklearn.linear_model as sk

#BTC_RSR = BTC[1106:]

import pandas as pd
path = '/content/gdrive/MyDrive/digitalskola/dataset/babp/lengkap/ticker_df_symbol_LITUSDT.csv'
LIT = pd.read_csv(path)

LIT.rename(columns = {"Open Time":"Date"}, inplace=True)
#RSR = RSR.set_index('Date')
#LIT = LIT[['Close']]
LIT.drop(columns='Unnamed: 0', inplace=True)
LIT.drop(columns='Ignore', inplace=True)
LIT.rename(columns = {'Close':'Close_LIT'}, inplace=True)
LIT.shape

LIT.drop(columns='Close Time', inplace=True)

LIT.set_index(LIT['Date'])

sp500.index = pd.to_datetime(sp500.index)

sns.pairplot(LIT)

LIT.plot.line(y="Close_LIT", use_index=True)

LIT.rename(columns = {'Close_LIT':'Close'}, inplace=True)

LIT["Tomorrow"] = LIT["Close"].shift(-1)

LIT["Target"] = (LIT["Tomorrow"] > LIT["Close"]).astype(int)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)

train = LIT.iloc[:-100]
test = LIT.iloc[-100:]

#predictors = ["Close", "Volume", "Open", "High", "Low", "Quote Asset Volume","Number of Trades","TB Base Volume","TB Quote Volume"]
predictors = ["Open", "High", "Low","Close", "Volume",]

model.fit(train[predictors], train["Target"])

train[predictors]

from sklearn.metrics import precision_score

preds = model.predict(test[predictors])
preds = pd.Series(preds, index=test.index)
precision_score(test["Target"], preds)

combined = pd.concat([test["Target"], preds], axis=1)
combined.plot()

def predict(train, test, predictors, model):
    model.fit(train[predictors], train["Target"])
    preds = model.predict(test[predictors])
    preds = pd.Series(preds, index=test.index, name="Predictions")
    combined = pd.concat([test["Target"], preds], axis=1)
    return combined

def backtest(data, model, predictors, start=2500, step=250):
    all_predictions = []

    for i in range(start, data.shape[0], step):
        train = data.iloc[0:i].copy()
        test = data.iloc[i:(i+step)].copy()
        predictions = predict(train, test, predictors, model)
        all_predictions.append(predictions)
    
    return pd.concat(all_predictions)

def backtest(data, model, predictors, start=2500, step=250):
    all_predictions = []

    for i in range(start, data.shape[0], step):
        train = data.iloc[0:i].copy()
        test = data.iloc[i:(i+step)].copy()
        predictions = predict(train, test, predictors, model)
        all_predictions.append(predictions)
    
    return pd.concat(all_predictions)

horizons = [2,5,20,60,50]
new_predictors = []

for horizon in horizons:
    rolling_averages = LIT.rolling(horizon).mean()
    
    ratio_column = f"Close_Ratio_{horizon}"
    LIT[ratio_column] = LIT["Close"] / rolling_averages["Close"]
    
    trend_column = f"Trend_{horizon}"
    LIT[trend_column] = LIT.shift(1).rolling(horizon).sum()["Target"]
    
    new_predictors+= [ratio_column, trend_column]

model = RandomForestClassifier(n_estimators=200, min_samples_split=50, random_state=1)

def predict(train, test, predictors, model):
    model.fit(train[predictors], train["Target"])
    preds = model.predict_proba(test[predictors])[:,1]
    preds[preds >=.6] = 1
    preds[preds <.6] = 0
    preds = pd.Series(preds, index=test.index, name="Predictions")
    combined = pd.concat([test["Target"], preds], axis=1)
    return combined

predictions = backtest(LIT, model, new_predictors)





"""#### test KNC - internet"""

!pip install yfinance

import yfinance as yf
import pandas as pd
import os

if os.path.exists("sp500.csv"):
    sp500 = pd.read_csv("sp500.csv", index_col=0)
else:
    sp500 = yf.Ticker("^GSPC")
    sp500 = sp500.history(period="max")
    sp500.to_csv("sp500.csv")

sp500

sp500.index = pd.to_datetime(sp500.index)

sp500

sp500.plot.line(y="Close", use_index=True)

del sp500["Dividends"]
del sp500["Stock Splits"]

sp500["Tomorrow"] = sp500["Close"].shift(-1)

sp500["Target"] = (sp500["Tomorrow"] > sp500["Close"]).astype(int)

sp500 = sp500.loc["1990-01-01":].copy()

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(n_estimators=100, min_samples_split=100, random_state=1)

train = sp500.iloc[:-100]
test = sp500.iloc[-100:]

predictors = ["Close", "Volume", "Open", "High", "Low"]
model.fit(train[predictors], train["Target"])

from sklearn.metrics import precision_score

preds = model.predict(test[predictors])
preds = pd.Series(preds, index=test.index)
precision_score(test["Target"], preds)

combined = pd.concat([test["Target"], preds], axis=1)
combined.plot()

def predict(train, test, predictors, model):
    model.fit(train[predictors], train["Target"])
    preds = model.predict(test[predictors])
    preds = pd.Series(preds, index=test.index, name="Predictions")
    combined = pd.concat([test["Target"], preds], axis=1)
    return combined

def backtest(data, model, predictors, start=2500, step=250):
    all_predictions = []

    for i in range(start, data.shape[0], step):
        train = data.iloc[0:i].copy()
        test = data.iloc[i:(i+step)].copy()
        predictions = predict(train, test, predictors, model)
        all_predictions.append(predictions)
    
    return pd.concat(all_predictions)

predictions = backtest(sp500, model, predictors)

predictions["Predictions"].value_counts()

precision_score(predictions["Target"], predictions["Predictions"])











"""#TO_PDF fix menjadi several cdv on gdrive

>> To_pdf = fix sudah berhasil menggunakan semua data
"""

for symbols in ticker_df_symbol['symbol']:
    # nama variabel berdasarkan currency
    dataframe_identity = f'ticker_df_symbol_{symbols}' # hanya sebuah string
    
    # string / nama variable, dijadikan variable
    
    # saya gunakan string yang telah didefine sebelumnya, menjadi nama variable
    globals()[dataframe_identity] = pd.DataFrame( client.get_historical_klines(symbols, Client.KLINE_INTERVAL_1DAY, '1 Jan 2011') )
    globals()[dataframe_identity].columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']
    globals()[dataframe_identity]['Open Time'] = pd.to_datetime(globals()[dataframe_identity]['Open Time']/1000, unit='s')
    # globals()[dataframe_identity].to_csv(globals()[dataframe_identity].csv', index=False)
    #globals()[dataframe_identity].to_csv(eval({symbols}),index=False)
    if ((globals()[dataframe_identity].shape[0]) >= 500):
      eval(f'ticker_df_symbol_{symbols}').to_csv('/content/gdrive/MyDrive/digitalskola/dataset/babp/Ticker500/'f'ticker_df_symbol_{symbols}.csv')
    #hist_df['Close Time'] = pd.to_datetime(hist_df['Close Time']/1000, unit='s')
    #historical = client.get_historical_klines('ETHBTC', Client.KLINE_INTERVAL_1DAY, '1 Jan 2011')

    # ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    #'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']

""">> To_pdf = COBA menggunakan filter"""

for symbols in ticker_df_symbol['symbol']:
    # nama variabel berdasarkan currency
    dataframe_identity = f'ticker_df_symbol_{symbols}' # hanya sebuah string
    
    # string / nama variable, dijadikan variable
    
    # saya gunakan string yang telah didefine sebelumnya, menjadi nama variable
    globals()[dataframe_identity] = pd.DataFrame( client.get_historical_klines(symbols, Client.KLINE_INTERVAL_1DAY, '1 Jan 2011') )
    globals()[dataframe_identity].columns = ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']
    globals()[dataframe_identity]['Open Time'] = pd.to_datetime(globals()[dataframe_identity]['Open Time']/1000, unit='s')
    # globals()[dataframe_identity].to_csv(globals()[dataframe_identity].csv', index=False)
    #globals()[dataframe_identity].to_csv(eval({symbols}),index=False)
    if ((globals()[dataframe_identity].shape[0]) >= 1000) & ((globals()[dataframe_identity].shape[0]) <= 2100):
      eval(f'ticker_df_symbol_{symbols}').to_csv('/content/gdrive/MyDrive/digitalskola/dataset/babp/test2'f'ticker_df_symbol_{symbols}.csv')
    #hist_df['Close Time'] = pd.to_datetime(hist_df['Close Time']/1000, unit='s')
    #historical = client.get_historical_klines('ETHBTC', Client.KLINE_INTERVAL_1DAY, '1 Jan 2011')

    # ['Open Time', 'Open', 'High', 'Low', 'Close', 'Volume', 'Close Time', 'Quote Asset Volume', 
                    #'Number of Trades', 'TB Base Volume', 'TB Quote Volume', 'Ignore']

""">> Ticker yang memiliki same shape dan rows"""

#ngambil dari ticker_df_symbol untuk list apa saja yang crypto di dataframe
for symbols in ticker_df['symbol']:
   dataframe_identity = f'ticker_df_symbol_{symbols}'
   if (dataframe_identity == arraysymbol):
     print("true")

dataframe_identity

dataframe_identity

"""#Clustring After get 2000 crypto into several dataframe"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.cluster import KMeans
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from matplotlib import pyplot as plt
# %matplotlib inline

"""#Time Series

https://www.machinelearningplus.com/time-series/time-series-analysis-python/
"""

ticker_df_symbol_BTCUSDT_time = ticker_df_symbol_BTCUSDT.copy()

ticker_df_symbol_BTCUSDT_time['Close'] = ticker_df_symbol_BTCUSDT_time['Close'].apply(pd.to_numeric)

ticker_df_symbol_BTCUSDT_time

# Time series data source: fpp pacakge in R.
import matplotlib.pyplot as plt

# Draw Plot
def plot_df(ticker_df_symbol_BTCUSDT_time, x, y, title="", xlabel='Open Time', ylabel='Close', dpi=100):
    plt.figure(figsize=(16,5), dpi=dpi)
    plt.plot(x, y, color='tab:red')
    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)
    plt.show()

plot_df(df, x=ticker_df_symbol_BTCUSDT_time.index, y=ticker_df_symbol_BTCUSDT_time.Close, title='Time Series BTC')

"""Since all values are positive, you can show this on both sides of the Y axis to emphasize the growth."""

ticker_df_symbol_BTCUSDT_time['Open Time'] = pd.to_datetime(ticker_df_symbol_BTCUSDT_time['Open Time'])

ticker_df_symbol_BTCUSDT_time1 = ticker_df_symbol_BTCUSDT_time.copy()

ticker_df_symbol_BTCUSDT_time1.rename(columns = {'Open Time' : 'Date'}, inplace = True)

# Prepare data
ticker_df_symbol_BTCUSDT_time1['Date'] = pd.to_datetime(ticker_df_symbol_BTCUSDT_time1['Date'])

# extract year from date

ticker_df_symbol_BTCUSDT_time1['Year'] = ticker_df_symbol_BTCUSDT_time1['Date'].dt.year
ticker_df_symbol_BTCUSDT_time1['Year']

# extract month from date

ticker_df_symbol_BTCUSDT_time1['Month'] = ticker_df_symbol_BTCUSDT_time1['Date'].dt.month
ticker_df_symbol_BTCUSDT_time1['Month'].head()

years_v = ticker_df_symbol_BTCUSDT_time1['Year'].unique()

Close_v = ticker_df_symbol_BTCUSDT_time1['Close'].values

# Prep Colors
import matplotlib as mpl
np.random.seed(100)
mycolors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), years_v, replace=False)

ticker_df_symbol_BTCUSDT_time1.drop('Year', axis=1, inplace=True)
ticker_df_symbol_BTCUSDT_time1.drop('Month', axis=1, inplace=True)

# Prepare data
ticker_df_symbol_BTCUSDT_time1['year'] = [d.year for d in ticker_df_symbol_BTCUSDT_time1.Date]

ticker_df_symbol_BTCUSDT_time1['month'] = [d.strftime('%b') for d in ticker_df_symbol_BTCUSDT_time1.Date]

years = ticker_df_symbol_BTCUSDT_time1['year'].unique()

# Draw Plot
plt.figure(figsize=(16,12), dpi=80)
e = np.linspace(0.001, 4, 1000)
for i, y in enumerate(years):
    if i > 0:        
        plt.plot('month', 'Close', data=ticker_df_symbol_BTCUSDT_time1.loc[ticker_df_symbol_BTCUSDT_time1.year==y, :], color=mycolors[i], label=y)
        plt.text(ticker_df_symbol_BTCUSDT_time1.loc[ticker_df_symbol_BTCUSDT_time1.year==y, :].shape[0]-.9, ticker_df_symbol_BTCUSDT_time1.loc[ticker_df_symbol_BTCUSDT_time1.year==y, 'Close'][-1:].values[0], y, fontsize=12, color=mycolors[i])

"""## Boxplot of Month-wise (Seasonal) and Year-wise (trend) Distribution


"""

import seaborn as sns
# Draw Plot
fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)
sns.boxplot(x='year', y='Close', data=ticker_df_symbol_BTCUSDT_time1, ax=axes[0])
sns.boxplot(x='month', y='Close', data=ticker_df_symbol_BTCUSDT_time1.loc[~ticker_df_symbol_BTCUSDT_time1.year.isin([2017, 2022]), :])

# Set Title
axes[0].set_title('Year-wise Box Plot\n(The Trend)', fontsize=18); 
axes[1].set_title('Month-wise Box Plot\n(The Seasonality)', fontsize=18)
plt.show()

# Prepare data
years = ticker_df_symbol_BTCUSDT_time1['year'].unique()

import seaborn as sns
# Draw Plot
fig, axes = plt.subplots(1, 2, figsize=(20,7), dpi= 80)
sns.boxplot(x='year', y='Close', data=ticker_df_symbol_BTCUSDT_time1, ax=axes[0])
sns.boxplot(x='month', y='Close', data=ticker_df_symbol_BTCUSDT_time1.loc[~ticker_df_symbol_BTCUSDT_time1.year.isin([2017, 2022]), :])

# Set Title
axes[0].set_title('Year-wise Box Plot\n(The Trend)', fontsize=18); 
axes[1].set_title('Month-wise Box Plot\n(The Seasonality)', fontsize=18)
plt.show()

"""The boxplots make the year-wise and month-wise distributions evident,
Also, in a month-wise boxplot, the months of January, June ,November and December clearly has higher Voladility market.

So far, we have seen the similarities to identify the pattern. Now, how to find out any deviations from the usual pattern?

A trend is observed when there is an increasing or decreasing slope observed in the time series. Whereas seasonality is observed when there is a distinct repeated pattern observed between regular intervals due to seasonal factors. It could be because of the month of the year, the day of the month, weekdays or even time of the day.

However, It is not mandatory that all time series must have a trend and/or seasonality. A time series may not have a distinct trend but have a seasonality. The opposite can also be true.

So, a time series may be imagined as a combination of the trend, seasonality and the error terms.

untuk upload csv
"""

from google.colab import drive

#drive.mount('/content/drive')
path = '/content/drive/My Drive/ticker_df_symbol_BTCUSDT_time1.csv'

with open(path, 'w', encoding = 'utf-8-sig') as f:
  ticker_df_symbol_BTCUSDT_time1.to_csv(f)

df223 = pd.DataFrame(ticker_df_symbol_BTCUSDT_time1)
print(str(df223['Date'][0:len(df223)]))

""">> Contionue"""

# Using scipy: Subtract the line of best fit
from scipy import signal
df = pd.read_csv('/content/drive/My Drive/ticker_df_symbol_BTCUSDT_time1.csv', parse_dates=['Date'])
detrended = signal.detrend(df.Close.values)
plt.plot(detrended)
plt.title('Drug Sales detrended by subtracting the least squares fit', fontsize=16)

from pandas import read_csv
from pandas import datetime
from sklearn.linear_model import LinearRegression
from matplotlib import pyplot
import numpy
 
def parser(x):
	return datetime.strptime('190'+x, '%Y-%m')
 
series = read_csv('/content/drive/My Drive/ticker_df_symbol_BTCUSDT_time1.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)

# Using statmodels: Subtracting the Trend Component.
from statsmodels.tsa.seasonal import seasonal_decompose
df = pd.read_csv('/content/drive/My Drive/ticker_df_symbol_BTCUSDT_time1.csv', parse_dates=['Date'], index_col='Date')
result_mul = seasonal_decompose(df['Close'], model='multiplicative', extrapolate_trend='freq')
detrended = df.Close.values - result_mul.trend
plt.plot(detrended)
plt.title('Volatility Market Behavior to BTC USDT', fontsize=16)

# Plot
plt.rcParams.update({'figure.figsize': (10,10)})
result_mul.plot().suptitle('Multiplicative Decompose', fontsize=22)
result_add.plot().suptitle('Additive Decompose', fontsize=22)
plt.show()

testest.isna().sum()



"""## Patterns in a time series

Any time series may be split into the following components: Base Level + Trend + Seasonality + Error

#Kmeans
"""

pip install pycaret

pip install pycaret[full]

dataset = result1

data = dataset.sample(frac=0.95, random_state=786)
data_unseen = dataset.drop(data.index)

data.reset_index(drop=True, inplace=True)
data_unseen.reset_index(drop=True, inplace=True)

print('Data for Modeling: ' + str(data.shape))
print('Unseen Data For Predictions: ' + str(data_unseen.shape))

from pycaret.clustering import *

exp_clu101 = setup(data, normalize = True,
                   session_id = 1)

dataset[['symbol_only_usdtRSRUSDT']]

kmeans = create_model('kmeans')

print(kmeans)

kmodes = create_model('kmodes', num_clusters = 6)

kmodes = create_model('kmodes', num_clusters = 8)

print(kmodes)

models()

"""#### Asign Model """

kmean_results = assign_model(kmeans)
kmean_results.head()

kmean_results.to_csv('/content/gdrive/MyDrive/digitalskola/dataset/babp/cluster/cluster.csv')

"""#### Ploting model """

plot_model(kmeans)

"""# Model

##RSR
"""



"""# TEST KNC"""

hist_df_KNC

hist_df_KNC['Open Time'] = pd.to_datetime(hist_df_KNC['Open Time']/1000)

import pandas as pd
hist_df_KNC1 = hist_df_KNC.set_index('Open Time')
hist_df_KNC1.head(5)



hist_df_KNC1.drop('Ignore', axis=1, inplace=True)

pip install tensorflow

from tensorflow.keras import models, layers, utils, backend as K
import matplotlib.pyplot as plt
#import shap

df = hist_df_KNC

df.rename(columns={'Open Time':'Date'}, inplace=True)

df["Date"]=pd.to_datetime(df.Date,format="%Y-%m-%d")
df.index=df['Date']
plt.figure(figsize=(16,8))
plt.plot(df["Close"],label='Close Price history')

data=df.sort_index(ascending=True,axis=0)
new_dataset=pd.DataFrame(index=range(0,len(df)),columns=['Date','Close'])
for i in range(0,len(data)):
    new_dataset["Date"][i]=data['Date'][i]
    new_dataset["Close"][i]=data["Close"][i]









"""# Model random forest LIT

https://amete.github.io/DataSciencePortfolio/Udemy/Python-DS-and-ML-Bootcamp/Linear_Regression_Project.html
"""

from sklearn.model_selection import train_test_split

predictors = ["Open", "High", "Low","Volume"]
X = LIT[predictors]
y = LIT['Close']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

from sklearn.linear_model import LinearRegression

lm = LinearRegression()

lm.fit(X_train,y_train)

lm.coef_

"""##Predicting Test DataÂ¶"""

predictions = lm.predict(hist_df_LITX)
predictions

hist_df_LIT

hist_df_LITX

plt.scatter(x = hist_df_LITY, y = predictions)
plt.xlabel('Y Test')
plt.ylabel('Predicted Y')

"""@predict ke2

## Evaluate model
"""

from sklearn import metrics
from math import sqrt
import numpy as np

print('MAE:', 
      metrics.mean_absolute_error(y_test, predictions), ' ',
      (1./len(y_test))*(sum(abs(y_test-predictions))))
print('MSE:', 
      metrics.mean_squared_error(y_test, predictions), ' ',
      (1./len(y_test))*(sum((y_test-predictions)**2)))
print('RMSE:', 
      np.sqrt(metrics.mean_squared_error(y_test, predictions)), ' ',
      sqrt((1./len(y_test))*(sum((y_test-predictions)**2))))

#Residuals
sns.distplot((y_test-predictions), bins = 50)

df = pd.DataFrame( data = lm.coef_, columns = ['Coefficient'] ,index = X_train.columns)
df.head()

